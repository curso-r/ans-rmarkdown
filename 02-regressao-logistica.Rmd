---
title: "R Notebook"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE, hide = TRUE)
```

# Referências

- [R for Data Science](https://r4ds.had.co.nz/)
- [Tidy Modeling With R](https://www.tmwr.org/)
- [pacote {slider}](https://davisvaughan.github.io/slider/)
- [Feature Engineering And Selection](http://www.feat.engineering/)
- [Introduction To Statistical Learning](https://static1.squarespace.com/static/5ff2adbe3fe4fe33db902812/t/6062a083acbfe82c7195b27d/1617076404560/ISLR%2BSeventh%2BPrinting.pdf)
- [Material do Curso de Machine Learning da Curso-R](https://github.com/curso-r/202104-intro-ml)

```{r}
# pacotes ---------------
library(tidyverse)
library(GGally)
```

# Conexão R e SQL

```{r}
# Exemplo de conexão com um MariaDB (também conhecido como MySQL) remoto.
con_mariadb <- DBI::dbConnect(
  RMariaDB::MariaDB(), 
  host = "relational.fit.cvut.cz", 
  port = 3306, 
  username = "guest", 
  password = "relational",
  dbname = "financial"
)
DBI::dbListTables(con_mariadb)
```

```{r}
# Conexao com SQLite --------------------------------------------------------------
con <- DBI::dbConnect(RSQLite::SQLite(), "dados_consultoria.db")
# Acessando o SQL a partir do R ------------------------------------------------
# computação é feita lá no servidor.
tbl(con, "indicadores") %>%
  count(id)
# dá pra consultar a query de SQL que rodou lá no servidor.
tbl(con, "indicadores") %>%
  count(id) %>%
  show_query()
# passando do SQL pro R --------------------------------------------------------
# collect() faz o download pro computado local (não estamos mais usando o servidor).
indicadores <- tbl(con, "indicadores") %>% collect()
# PS: o SQLite não tem formato de datas, então tem que transformar em data quando vem pro R. Esse problema não tem no MySQL ou no SQL Server.
indicadores <- indicadores %>%
  mutate(
    data = as.Date(data)
  )
```


# Exemplo de manipulação de dados

*Informação 1* - Sobre os IDs, o cliente informou que deveria ter apenas uma linha para cada trinca (id-ano-mes).
Por conta de uma inconsistência, poderia acontecer de virem duas ou mais linhas para o mesma trinca (id-ano-mes).
O correto é ter apenas uma linha apenas. Eles disseram que a linha com o maior valor de agendamento tem mais chance
de ser a correta.


```{r}
# Solução: arrange() + distinct()
indicadores <- indicadores %>%
  dplyr::arrange(desc(agendamento)) %>%
  dplyr::distinct(id, ano, mes, .keep_all = TRUE)
```


*Informação 2* - Sobre as séries mensais, o cliente informou que:

1) IDs podem ter início e fim distintos.
2) A série de meses de um ID não teve ter mês faltante entre seu início e seu fim,
   porém, em virtude de problemas técnicos, pode haver perda de informação no meio
   do processo. Assim, nesses casos, orienta-se substituir o valor faltante pelo
   valor do mês anterior.



```{r}
# Olhando o problema dos meses faltantes
indicadores %>%
  ggplot(aes(x = data, y = id, colour = id)) +
  geom_point(size = 5) 
# Solução: {padr} + {tidyr} (exemplo com o id 970)
indicadores %>%
  dplyr::filter(id == 970) %>%
  dplyr::arrange(data) %>%
  padr::pad(interval = "month", group = "id")
indicadores_com_pad <- indicadores  %>%
  padr::pad(interval = "month", group = "id")  
# padr::pad() consertou
indicadores_com_pad %>%
  ggplot(aes(x = data, y = id, colour = id)) +
  geom_point(size = 5) 
# agora tem que preencher os NAs com fill.
indicadores_com_pad <- indicadores_com_pad %>%
  dplyr::arrange(id, data) %>%
  tidyr::fill(agendamento:cidade) %>%
  dplyr::mutate(
    # mes e ano não dá pra preencher com fill diretamente
    mes = as.character(lubridate::month(data)),
    ano = as.character(lubridate::year(data))
  )
```


# Exemplos de Criação de Features janeladas

```{r}
 # features no tempo (exemplo) ---------------------
teste <- indicadores_com_pad %>% 
  filter(id %in% c(406, 420), data %>% between(as.Date("2019-01-01"), as.Date("2019-04-01"))) %>%
  select(id, data)
# transformacoes
teste %>%
  arrange(id, data) %>%
  group_by(id) %>%
  mutate(
    x = 1:n(),
    a = cumsum(x),
    b = lag(x),
    c = lag(x, n = 2),
    d = lead(x),
    e = slider::slide_dbl(x, mean, .before = 1, .after = 0),
    f = slider::slide_dbl(x, mean, .before = 0, .after = 0),
    h = x/lag(x)
  )
```


# Fluxo de Trabalho do Tidymodels

## PASSO 0) CARREGAR AS BASES

```{r}
# https://github.com/gastonstat/CreditScoring 
# http://bit.ly/2kkBFrk
library(modeldata)
data(credit_data)
glimpse(credit_data) # German Risk

credit_data %>% count(Status)

# trazer do servidor para o R (memória do computador local)
credit_data <- credit_data %>% collect()
```

## PASSO 1) BASE TREINO/TESTE

```{r}
set.seed(1)
credit_initial_split <- initial_split(credit_data, strata = "Status", prop = 0.75)

credit_train <- training(credit_initial_split)
credit_test  <- testing(credit_initial_split)
```

## PASSO 2) EXPLORAR A BASE

```{r}
skimr::skim(credit_train)
```

```{r}
visdat::vis_miss(credit_train)
```

```{r}
credit_train %>% 
  select(where(is.numeric)) %>% 
  cor(use = "p") %>% 
  corrplot::corrplot()
```

```{r, fig.height=12, message=FALSE, warning=FALSE}
credit_train %>% 
  select(where(is.numeric), Status) %>%
  ggpairs(aes(colour = Status))
```

```{r, fig.height=8}
contagens <- credit_train %>% 
  select(c(where(is.factor), Status)) %>%
  pivot_longer(-Status, names_to = "variavel", values_to = "valor") %>%
  count(Status, variavel, valor)

# tabela
contagens %>%
  pivot_wider(names_from = Status, values_from = n)
```

```{r, fig.height=8}
contagens %>%
  ggplot(aes(y = valor, x = n, fill = Status)) +
  geom_col(position = "fill") +
  geom_label(aes(label = n), position = position_fill(vjust = 0.5)) +
  facet_wrap(~variavel, scales = "free_y") +
  ggtitle("Status vs. Variáveis Categóricas")
```

```{r, fig.height=8}
credit_train %>% 
  select(c(where(is.numeric), Status)) %>%
  pivot_longer(-Status, names_to = "variavel", values_to = "valor") %>%
  ggplot(aes(y = Status, x = valor, fill = Status)) +
  geom_boxplot() +
  facet_wrap(~variavel, scales = "free_x") +
  ggtitle("Status vs. Variáveis Numéricas")
```

```{r, fig.height=8}
credit_train %>% 
  select(c(where(is.numeric), Status)) %>%
  pivot_longer(-Status, names_to = "variavel", values_to = "valor") %>%
  ggplot(aes(y = Status, x = valor, fill = Status)) +
  geom_boxplot() +
  facet_wrap(~variavel, scales = "free_x") +
  scale_x_log10() +
  ggtitle("Status vs. Variáveis Numéricas NA ESCALA LOG")
```

```{r, fig.height=8}
credit_train %>% 
  select(c(where(is.numeric), Status)) %>%
  pivot_longer(-Status, names_to = "variavel", values_to = "valor") %>%
  ggplot(aes(x = valor, colour = Status)) +
  stat_ecdf() +
  facet_wrap(~variavel, scales = "free_x") +
  labs(title = "Status vs. Variáveis Numéricas",
       subtitle = "Distribuição Acumulada")
```

```{r, fig.height=13}
grafico_de_barras_das_vars_continuas <- function(dados, barras = 10) {
  dados %>% 
    select(c(where(is.numeric), Status)) %>%
    pivot_longer(-Status, names_to = "variavel", values_to = "valor") %>%
    dplyr::group_by(variavel) %>%
    dplyr::mutate(
      valor = factor(dplyr::ntile(valor, barras), levels = 1:barras)
    ) %>%
    dplyr::count(Status, variavel, valor) %>%
    ggplot(aes(y = (valor), x = n, fill = Status)) +
    geom_col(position = "fill") +
    geom_label(aes(label = n), position = position_fill(vjust = 0.5)) +
    facet_wrap(~variavel, scales = "free_y", ncol = 3) +
    ggtitle("Status vs. Variáveis Categóricas")
}

grafico_de_barras_das_vars_continuas(credit_train, barras = 12)
```

## PASSO 3) DATAPREP

```{r}
# criando a receita
credit_recipe <- recipe(Status ~ ., data = credit_train) %>%
  step_zv(all_predictors()) %>%
  step_mutate(
    Home = ifelse(is.na(Home), "other", as.character(Home)),
    Job = ifelse(is.na(Job), "partime", as.character(Job)),
    Marital = ifelse(is.na(Marital), "married",as.character(Marital)),
    Assets = ifelse(is.na(Assets), min(Assets, na.rm = TRUE), Assets),
    Income = ifelse(is.na(Income), min(Income, na.rm = TRUE), Income),
  ) %>%
  step_impute_bag(Debt, impute_with = imp_vars(Income, Price, Amount)) %>%
  step_normalize(all_numeric()) %>%
  step_novel(all_nominal_predictors())

credit_recipe
```

```{r, fig.height=15}
# criando a base preparada
credit_preparada <- bake(prep(credit_recipe), new_data = NULL)
```

```{r, fig.height=8}
# olhando a base preparada
visdat::vis_miss(credit_preparada)
```

```{r, fig.height=13}
credit_preparada %>% 
  select(c(where(is.factor), Status)) %>%
  pivot_longer(-Status, names_to = "variavel", values_to = "valor") %>%
  count(Status, variavel, valor) %>%
  ggplot(aes(y = valor, x = n, fill = Status)) +
  geom_col(position = "fill") +
  geom_label(aes(label = n), position = position_fill(vjust = 0.5)) +
  facet_wrap(~variavel, scales = "free_y", ncol = 3) +
  ggtitle("Status vs. Variáveis Categóricas")
```

```{r, fig.height=10}
grafico_de_barras_das_vars_continuas(credit_preparada)
```

```{r}
# finalizando a receita com dummies
credit_recipe <- credit_recipe %>%
  step_dummy(all_nominal_predictors())
```

## PASSO 4) MODELO

```{r}
# Definição de 
# a) a f(x): logistc_reg()
# b) modo (natureza da var resp): classification
# c) hiperparametros que queremos tunar: penalty = tune()
# d) hiperparametros que não queremos tunar: mixture = 1 # LASSO
# e) o motor que queremos usar: glmnet
credit_lr_model <- logistic_reg(penalty = tune(), mixture = 1) %>%
  set_mode("classification") %>%
  set_engine("glmnet")

# workflow
credit_wf <- workflow() %>% add_model(credit_lr_model) %>% add_recipe(credit_recipe)
```

## PASSO 5) TUNAGEM DE HIPERPARÂMETROS

```{r}
# a) bases de reamostragem para validação: vfold_cv()
# b) (opcional) grade de parâmetros: parameters() %>% update() %>% grid_regular()
# c) tune_grid(y ~ x + ...)
# d) escolha das métricas (rmse, roc_auc, etc)
# d) collect_metrics() ou autoplot() para ver o resultado
credit_resamples <- vfold_cv(credit_train, v = 5)

credit_lr_tune_grid <- tune_grid(
  credit_wf,
  resamples = credit_resamples,
  grid = 40,
  metrics = metric_set(
    accuracy, 
    roc_auc
    # kap, # KAPPA 
    # precision, 
    # recall, 
    # f_meas, 
    # mn_log_loss #binary cross entropy
  )
)

autoplot(credit_lr_tune_grid)
show_best(credit_lr_tune_grid)
collect_metrics(credit_lr_tune_grid)
```

## PASSO 6) DESEMPENHO DO MODELO FINAL

```{r}
# a) extrai melhor modelo com select_best()
# b) finaliza o modelo inicial com finalize_model()
# c) ajusta o modelo final com todos os dados de treino (bases de validação já era)
credit_lr_best_params <- select_best(credit_lr_tune_grid, "roc_auc")
credit_wf <- credit_wf %>% finalize_workflow(credit_lr_best_params)

credit_lr_last_fit <- last_fit(
  credit_wf,
  credit_initial_split
)

credit_lr_last_fit
```

```{r}
# métricas de desempenho
collect_metrics(credit_lr_last_fit)
```

```{r}
# base de teste com as predições
collect_predictions(credit_lr_last_fit)
```

### Variáveis importantes

```{r}
# extrai o modelo do objeto de ajuste
credit_lr_last_fit_model <- pull_workflow_fit(credit_lr_last_fit$.workflow[[1]])

# tabela de betas
vi(credit_lr_last_fit_model)
```

```{r}
# gráfico de Variable Importances
vip(credit_lr_last_fit_model)
```

```{r}
# outra maneira de pegar os betas: broom::tidy()
betas <- broom::tidy(credit_lr_last_fit_model)
betas %>% arrange(desc(abs(estimate)))
```

### Métricas de desempenho

```{r}
collect_metrics(credit_lr_last_fit)

credit_test_preds <- collect_predictions(credit_lr_last_fit)

# roc
credit_roc_curve <- credit_test_preds %>% roc_curve(Status, .pred_bad)
autoplot(credit_roc_curve)
```

```{r}
# confusion matrix
credit_test_preds %>%
  mutate(
    Status_class = factor(if_else(.pred_bad > 0.6, "bad", "good"))
  ) %>%
  conf_mat(Status, Status_class)
```

### Gráficos extras

```{r, fig.width=5, fig.height=6}
# risco por faixa de score (multiplas notas de corte)]
percentis = 15
credit_test_preds %>%
  mutate(
    score =  factor(ntile(.pred_bad, percentis))
  ) %>%
  count(score, Status) %>%
  ggplot(aes(y = score, x = n, fill = Status)) +
  geom_col(position = "fill") +
  geom_label(aes(label = n), position = "fill")
```

```{r, fig.width=9, fig.height=6}
# gráfico sobre os da classe "bad"
credit_test_preds %>%
  mutate(
    score = factor(ntile(.pred_bad, percentis))
  ) %>%
  filter(Status == "bad") %>%
  group_by(score) %>%
  summarise(
    n = n(),
    media = mean(.pred_bad)
  ) %>%
  mutate(p = n/sum(n)) %>%
  ggplot(aes(x = p, y = score)) +
  geom_col() +
  geom_label(aes(label = scales::percent(p)), hjust = 1.1) +
  geom_vline(xintercept = 1/percentis, colour = "red", linetype = "dashed", size = 1)
```

## PASSO 7) MODELO FINAL

### Ajuste final

```{r}
credit_final_lr_model <- fit(credit_wf, credit_data)
```

### Variáveis do modelo final

```{r}
# extrai o modelo do objeto de ajuste
credit_final_lr_fit <- credit_final_lr_model$fit$fit

# tabela de betas
vi(credit_final_lr_fit)
vip(credit_final_lr_fit)

# salva tudo no computador
write_rds(credit_final_lr_model, "credit_final_lr_model.rds")
write_rds(credit_lr_last_fit, "credit_lr_last_fit.rds")
```

### predições

```{r}
# predições
dados_novos <- testing(credit_initial_split)
predict(credit_final_lr_model, new_data = dados_novos, type = "prob")

# colocar no BD
dados_novos <- bind_cols(
  dados_novos,
  predict(credit_final_lr_model, new_data = dados_novos, type = "prob")
)

# salvar no excel
writexl::write_xlsx(dados_novos, "dados_novos.xlsx")

# salvar no SQL
copy_to(con, dados_novos, overwrite = TRUE, temporary = FALSE)
dbListTables(con)
```

# [EXEMPLO DE DASHBOARD (link)](https://curso-r.github.io/202104-intro-ml/exemplos/11-report-credit-data.html)
